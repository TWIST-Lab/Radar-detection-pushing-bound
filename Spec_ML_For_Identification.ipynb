{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Reshape, Conv2DTranspose, Activation, ReLU\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'D:\\MILCOM_2025\\Spec_BIN_data_SNR-5'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_BIN_data_SNR_0'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_BIN_data_SNR5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r\"D:\\MILCOM_2025\\Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get all file paths and labels\n",
    "all_files = sorted(glob(os.path.join(path, '*', '*')))\n",
    "all_labels = [os.path.basename(os.path.dirname(f)) for f in all_files]\n",
    "class_names = sorted(set(all_labels))\n",
    "label_to_index = {label: idx for idx, label in enumerate(class_names)}\n",
    "all_indices = [label_to_index[label] for label in all_labels]\n",
    "\n",
    "# Step 2: Convert to numpy arrays\n",
    "all_files = np.array(all_files)\n",
    "all_indices = np.array(all_indices)\n",
    "\n",
    "# Step 3: Strict split — 50% train, 15% val, 35% test (or any ratio you want)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(all_files, all_indices, test_size=0.15, random_state=42, stratify=all_indices)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)  # 0.23 of 65% ≈ 15%\n",
    "\n",
    "# Step 4: Helper to load and preprocess image\n",
    "def preprocess_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image.set_shape((img_height, img_width, 3))\n",
    "    label = tf.one_hot(label, depth=len(class_names))\n",
    "    return image, label\n",
    "\n",
    "# Step 5: Build tf.data.Dataset for each split\n",
    "def build_dataset(file_paths, labels, is_train=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    ds = ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = build_dataset(X_train, y_train, is_train=True)\n",
    "val_ds = build_dataset(X_val, y_val, is_train=False)\n",
    "test_ds = build_dataset(X_test, y_test, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm no overlaps across splits\n",
    "def assert_disjoint(a, b, name1, name2):\n",
    "    overlap = set(a).intersection(set(b))\n",
    "    assert len(overlap) == 0, f\"Data leakage detected between {name1} and {name2}\"\n",
    "\n",
    "assert_disjoint(X_train, X_val, \"train\", \"val\")\n",
    "assert_disjoint(X_train, X_test, \"train\", \"test\")\n",
    "assert_disjoint(X_val, X_test, \"val\", \"test\")\n",
    "print(\"✅ All splits are 100% disjoint — no data leakage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(set(all_labels))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256, 256, 3)),\n",
    "  layers.MaxPooling2D(),\n",
    "\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'), \n",
    "  layers.MaxPooling2D(),\n",
    "\n",
    "  layers.Flatten(),\n",
    "\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, activation='softmax')  # Adjust class count if needed\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Time Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # Take one image from test_ds\n",
    "# for images, labels in test_ds.take(1):\n",
    "#     sample_image = images[0:1]\n",
    "#     break\n",
    "\n",
    "# # Warm up\n",
    "# _ = model.predict(sample_image)\n",
    "\n",
    "# # Run inference 1000 times and measure time\n",
    "# total_time = 0\n",
    "# num_runs = 1000\n",
    "# for _ in range(num_runs):\n",
    "#     start = time.time()\n",
    "#     _ = model.predict(sample_image, verbose=0)\n",
    "#     end = time.time()\n",
    "#     total_time += (end - start)\n",
    "\n",
    "# # Compute average inference time in milliseconds\n",
    "# avg_inference_time_ms = (total_time / num_runs) * 1000\n",
    "# print(f\"✅ Average inference time over {num_runs} runs: {avg_inference_time_ms:.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Create feature extractor from trained model\n",
    "feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "# Step 2: Extract features and labels from test_ds\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for images, label_batch in test_ds:\n",
    "    feats = feature_extractor(images)\n",
    "    features.append(feats.numpy())\n",
    "    labels.append(tf.argmax(label_batch, axis=1).numpy())\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "# Step 3: Apply 3D t-SNE\n",
    "tsne_3d = TSNE(n_components=3, perplexity=30, n_iter=1000, random_state=42).fit_transform(features)\n",
    "\n",
    "# Step 4: Define different angles (elevation, azimuth)\n",
    "view_angles = [\n",
    "    (20, 30),    # Default front view\n",
    "    (30, 120),   # Left rotated and above\n",
    "    (10, 210),   # Side view\n",
    "    (25, 300)    # Rear rotated\n",
    "]\n",
    "\n",
    "# Step 5: Create multi-angle subplots\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "palette = sns.color_palette(\"hsv\", len(class_names))\n",
    "\n",
    "for i, (elev, azim) in enumerate(view_angles):\n",
    "    ax = fig.add_subplot(2, 2, i + 1, projection='3d')\n",
    "    for j, class_name in enumerate(class_names):\n",
    "        idx = labels == j\n",
    "        ax.scatter(tsne_3d[idx, 0], tsne_3d[idx, 1], tsne_3d[idx, 2],\n",
    "                   label=class_name if i == 0 else \"\", s=40, edgecolor='black')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_title(f\"View {i+1} (elev={elev}, azim={azim})\", fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(\"TSNE-1\", fontsize=10, fontweight='bold')\n",
    "    ax.set_ylabel(\"TSNE-2\", fontsize=10, fontweight='bold')\n",
    "    ax.set_zlabel(\"TSNE-3\", fontsize=10, fontweight='bold')\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "# Add legend only once\n",
    "handles, legend_labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, legend_labels, loc='upper center', ncol=len(class_names), fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save the plot (optional)\n",
    "# plt.savefig(r\"D:\\MILCOM_2025\\Results\\tsne_3D_views_multiangle.png\", dpi=600)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Create feature extractor from trained model\n",
    "feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "# Step 2: Extract features and labels from test_ds\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for images, label_batch in test_ds:\n",
    "    feats = feature_extractor(images)\n",
    "    features.append(feats.numpy())\n",
    "    labels.append(tf.argmax(label_batch, axis=1).numpy())\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "# Step 3: Apply 3D t-SNE\n",
    "tsne_3d = TSNE(n_components=3, perplexity=30, max_iter=1000, random_state=42).fit_transform(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Plot only View 2 (elev=30, azim=120)\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "palette = sns.color_palette(\"hsv\", len(np.unique(labels)))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    idx = labels == i\n",
    "    ax.scatter(tsne_3d[idx, 0], tsne_3d[idx, 1], tsne_3d[idx, 2],\n",
    "               label=class_name, s=20)\n",
    "\n",
    "ax.view_init(elev=18, azim=107)\n",
    "# ax.set_title(\"t-SNE Projection\", fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel(\"Component 1\", fontsize=10, fontweight='bold')\n",
    "ax.set_ylabel(\"Component 2\", fontsize=10, fontweight='bold')\n",
    "ax.set_zlabel(\"Component 3\", fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.tick_params(axis='both', labelsize=10)\n",
    "ax.tick_params(axis='z', labelsize=10) \n",
    "# after your scatter() calls, but before plt.show()\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "\n",
    "my_labels = ['5G', 'Radar', 'Radar and 5G', ...] \n",
    "fig.legend(handles, my_labels,\n",
    "           loc='upper left',\n",
    "           bbox_to_anchor=(0.15, 0.88),\n",
    "           ncol=1,\n",
    "           fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r\"D:\\MILCOM_2025\\Results\\tsne for CNN Radar Detection data_New_binary.pdf\",  dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(r'D:\\SDRChallenge-main\\Demo\\DemoCNN.h5')\n",
    "# model = load_model(r'D:\\SDRChallenge-main\\Demo\\DemoCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = r\"D:\\SDRChallenge-main\\Plots\\Training_from_scratch_on_half_real_data\"  # Your desired folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.plot(training_accuracy, label='Training Accuracy', linestyle='--', linewidth=2)  # Thicker dotted curve\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy', linewidth=2)  # Thicker solid curve\n",
    "\n",
    "# Adding labels, title, and legend with larger and bold font\n",
    "plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.title('Training and Validation Accuracy', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Make the legend font size larger and bold using 'prop'\n",
    "plt.legend(fontsize=12, prop={'weight':'bold'})\n",
    "\n",
    "# Make tick labels bold and increase font size\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# Adding a grid with both major and minor grid lines\n",
    "plt.grid(True, which='both', linewidth=0.3)  # Smaller squares with thinner grid lines\n",
    "plt.minorticks_on()  # Enable minor ticks\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(save_dir, \"training_val_accuracy_curve_SNR-5_data_CNN.png\"), dpi=600)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that 'history' is the result of model training\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.plot(training_loss, label='Training Loss', linestyle='--', linewidth=2)  # Thicker dotted curve\n",
    "plt.plot(validation_loss, label='Validation Loss', linewidth=2)  # Thicker solid curve\n",
    "\n",
    "# Adding labels, title, and legend with larger and bold font\n",
    "plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
    "plt.title('Training and Validation Loss', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Make the legend font size larger and bold using 'prop'\n",
    "plt.legend(fontsize=12, prop={'weight':'bold'})\n",
    "\n",
    "# Make tick labels bold and increase font size\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# Adding a grid with both major and minor grid lines\n",
    "plt.grid(True, which='both', linewidth=0.3)  # Smaller squares with thinner grid lines\n",
    "plt.minorticks_on()  # Enable minor ticks\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(save_dir, \"training_val_loss_SNR-5_data_CNN.png\"), dpi=600)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make predictions on the validation dataset\n",
    "# Get the true labels and the predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))  # True labels\n",
    "    predictions = model.predict(images)\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))  # Predicted labels\n",
    "\n",
    "# Convert to numpy arrays for confusion matrix\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# radar_idx = class_names.index('Radar')\n",
    "# radar_5g_idx = class_names.index('5G_Radar')\n",
    "# Only5g_idx = class_names.index('5G')\n",
    "# Noise_idx = class_names.index('Noise')\n",
    "\n",
    "\n",
    "# # Step 4: Count the number of samples predicted as 'radar' and 'radar + 5G'\n",
    "# radar_count = (y_pred == radar_idx).sum()\n",
    "# radar_5g_count = (y_pred == radar_5g_idx).sum()\n",
    "\n",
    "# Calculate the total radar-related samples (radar + radar and 5G)\n",
    "# total_radar_count = radar_count + radar_5g_count\n",
    "\n",
    "# Print the results\n",
    "# print(f\"{radar_count} samples have radar signal.\")\n",
    "# print(f\"{radar_5g_count} samples have radar and 5G signal.\")\n",
    "# print(f\"{total_radar_count} samples have radar-related signal (including radar and radar + 5G).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 7))\n",
    "\n",
    "# Increase annotation size and make them bold\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=False, \n",
    "            annot_kws={\"size\": 20, \"fontweight\": \"bold\"})  # Set annotation font size and bold\n",
    "\n",
    "\n",
    "# Increase font size for axis labels and title\n",
    "plt.xlabel('Predicted Label ', fontsize=16, fontweight = 'bold')\n",
    "plt.ylabel('True Label', fontsize=16, fontweight = 'bold')\n",
    "\n",
    "# Additional step: Use plt.setp() to make tick labels bold\n",
    "plt.setp(plt.gca().get_xticklabels(), fontweight='bold')  # Set x-tick labels to bold\n",
    "plt.setp(plt.gca().get_yticklabels(), fontweight='bold')  # Set y-tick labels to bold\n",
    "\n",
    "# Increase tick label font size\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Save the figure with 400 DPI\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(save_dir, \"confusion_matrix_SNR-5_data_CNN.png\"), dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and normalize confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Create custom annotation: percentage with % for non-zeros, '0' for zeros\n",
    "annot = np.empty_like(cm_percent, dtype=object)\n",
    "for i in range(cm_percent.shape[0]):\n",
    "    for j in range(cm_percent.shape[1]):\n",
    "        if cm_percent[i, j] == 0:\n",
    "            annot[i, j] = '0'\n",
    "        else:\n",
    "            annot[i, j] = f\"{cm_percent[i, j]:.1f}%\"\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm_percent, annot=annot, fmt='', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names, cbar=False,\n",
    "            annot_kws={\"size\": 20, \"fontweight\": \"bold\"})\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=16, fontweight='bold')\n",
    "plt.setp(plt.gca().get_xticklabels(), fontweight='bold', fontsize=14)\n",
    "plt.setp(plt.gca().get_yticklabels(), fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(save_dir, \"confusion_matrix_SNR-5_data_CNN_in_percentage.png\"), dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_indices = np.where(y_true != y_pred)[0]\n",
    "print(\"Misclassified sample indices:\", misclassified_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = r'D:\\SDRChallenge-main\\SDR_data\\Binary_SNR-10\\Binary SNR-10 hough transform-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

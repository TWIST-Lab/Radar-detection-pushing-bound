{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, Model, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Reshape, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pdb\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import SGD,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'D:\\MILCOM_2025\\Spec_SNR-5'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_SNR0'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_SNR5'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_BIN_data_SNR-5'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_BIN_data_SNR_0'\n",
    "# path = r'D:\\MILCOM_2025\\Spec_BIN_data_SNR5'\n",
    "# path = r'D:\\MILCOM_2025\\IQ_BIN_data_SNR-5'\n",
    "# path = r'D:\\MILCOM_2025\\IQ_BIN_data_SNR_0'\n",
    "# path = r'D:\\MILCOM_2025\\IQ_BIN_data_SNR5'\n",
    "# path = r'D:\\MILCOM_2025\\Real_Data_All'\n",
    "# path = r'D:\\MILCOM_2025\\Real_BIN_Data'\n",
    "path = r'D:\\MILCOM_2025\\Spec_SNR-5_binary'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dir = r\"D:\\MILCOM_2025\\Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Get all file paths\n",
    "all_files = sorted(glob(os.path.join(path, '*', '*')))  # 'path' points to your root folder\n",
    "\n",
    "# Extract labels (folder names)\n",
    "all_labels = [os.path.basename(os.path.dirname(f)) for f in all_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get all file paths and labels\n",
    "all_files = sorted(glob(os.path.join(path, '*', '*')))\n",
    "all_labels = [os.path.basename(os.path.dirname(f)) for f in all_files]\n",
    "class_names = sorted(set(all_labels))\n",
    "label_to_index = {label: idx for idx, label in enumerate(class_names)}\n",
    "all_indices = [label_to_index[label] for label in all_labels]\n",
    "\n",
    "# Step 2: Convert to numpy arrays\n",
    "all_files = np.array(all_files)\n",
    "all_indices = np.array(all_indices)\n",
    "\n",
    "# Step 3: Strict split — 50% train, 15% val, 35% test (or any ratio you want)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(all_files, all_indices, test_size=0.15, random_state=42, stratify=all_indices)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)  # 0.23 of 65% ≈ 15%\n",
    "\n",
    "# Step 4: Helper to load and preprocess image\n",
    "def preprocess_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image.set_shape((img_height, img_width, 3))\n",
    "    label = tf.one_hot(label, depth=len(class_names))\n",
    "    return image, label\n",
    "\n",
    "# Step 5: Build tf.data.Dataset for each split\n",
    "def build_dataset(file_paths, labels, is_train=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    ds = ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if is_train:\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = build_dataset(X_train, y_train, is_train=True)\n",
    "val_ds = build_dataset(X_val, y_val, is_train=False)\n",
    "test_ds = build_dataset(X_test, y_test, is_train=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm no overlaps across splits\n",
    "def assert_disjoint(a, b, name1, name2):\n",
    "    overlap = set(a).intersection(set(b))\n",
    "    assert len(overlap) == 0, f\"Data leakage detected between {name1} and {name2}\"\n",
    "\n",
    "assert_disjoint(X_train, X_val, \"train\", \"val\")\n",
    "assert_disjoint(X_train, X_test, \"train\", \"test\")\n",
    "assert_disjoint(X_val, X_test, \"val\", \"test\")\n",
    "print(\"✅ All splits are 100% disjoint — no data leakage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(set(all_labels))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(\n",
    "    input_shape=(256, 256, 3),\n",
    "    patch_size=16,\n",
    "    projection_dim=64,\n",
    "    transformer_layers=4,\n",
    "    num_heads=4,\n",
    "    mlp_head_units=[128],\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=0.1,\n",
    "):\n",
    "    # Number of patches\n",
    "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
    "\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Patch creation and projection\n",
    "    x = layers.Conv2D(filters=projection_dim,\n",
    "                      kernel_size=patch_size,\n",
    "                      strides=patch_size,\n",
    "                      padding='valid')(inputs)\n",
    "    x = layers.Reshape((num_patches, projection_dim))(x)\n",
    "\n",
    "    # Positional embedding\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "    pos_embed = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)(positions)\n",
    "    x = x + pos_embed\n",
    "\n",
    "    # Transformer blocks\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization + MSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim)(x1, x1)\n",
    "        x2 = layers.Add()([x, attention_output])\n",
    "\n",
    "        # Layer normalization + MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        mlp_output = layers.Dense(projection_dim * 2, activation='gelu')(x3)\n",
    "        mlp_output = layers.Dropout(dropout_rate)(mlp_output)\n",
    "        mlp_output = layers.Dense(projection_dim)(mlp_output)\n",
    "        x = layers.Add()([x2, mlp_output])\n",
    "\n",
    "    # Final MLP head\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    for units in mlp_head_units:\n",
    "        x = layers.Dense(units, activation='gelu')(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Build and compile model\n",
    "model = create_vit_classifier()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train as before\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Create a model that outputs embeddings from the penultimate layer\n",
    "embedding_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "# Extract images and labels from the test dataset\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for batch_images, batch_labels in test_ds:\n",
    "    batch_features = embedding_model.predict(batch_images)\n",
    "    features.append(batch_features)\n",
    "    labels.append(batch_labels.numpy())\n",
    "\n",
    "# Concatenate all batches\n",
    "import numpy as np\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE with desired parameters\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "\n",
    "# Fit and transform the features\n",
    "tsne_results = tsne.fit_transform(features)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert one-hot encoded labels to class indices if necessary\n",
    "if labels.ndim > 1:\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap='tab10', alpha=0.7)\n",
    "plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.title(\"t-SNE Visualization of ViT Embeddings\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.plot(training_accuracy, label='Training Accuracy', linestyle='--', linewidth=2)  # Thicker dotted curve\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy', linewidth=2)  # Thicker solid curve\n",
    "\n",
    "# Adding labels, title, and legend with larger and bold font\n",
    "plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.title('Training and Validation Accuracy', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Make the legend font size larger and bold using 'prop'\n",
    "plt.legend(fontsize=12, prop={'weight':'bold'})\n",
    "\n",
    "# Make tick labels bold and increase font size\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# Adding a grid with both major and minor grid lines\n",
    "plt.grid(True, which='both', linewidth=0.3)  # Smaller squares with thinner grid lines\n",
    "plt.minorticks_on()  # Enable minor ticks\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir,\"training_val_accuracy_curve_SNR5_BIN_data_ViT.png\"), dpi=600)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that 'history' is the result of model training\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.plot(training_loss, label='Training Loss', linestyle='--', linewidth=2)  # Thicker dotted curve\n",
    "plt.plot(validation_loss, label='Validation Loss', linewidth=2)  # Thicker solid curve\n",
    "\n",
    "# Adding labels, title, and legend with larger and bold font\n",
    "plt.xlabel('Epochs', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
    "plt.title('Training and Validation Loss', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Make the legend font size larger and bold using 'prop'\n",
    "plt.legend(fontsize=12, prop={'weight':'bold'})\n",
    "\n",
    "# Make tick labels bold and increase font size\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# Adding a grid with both major and minor grid lines\n",
    "plt.grid(True, which='both', linewidth=0.3)  # Smaller squares with thinner grid lines\n",
    "plt.minorticks_on()  # Enable minor ticks\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir,\"training_val_Loss_curve_SNR5_BIN_data_ViT.png\"), dpi=600)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Make predictions on the validation dataset\n",
    "# Get the true labels and the predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))  # True labels\n",
    "    predictions = model.predict(images)\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))  # Predicted labels\n",
    "\n",
    "# Convert to numpy arrays for confusion matrix\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 7))\n",
    "\n",
    "# Increase annotation size and make them bold\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=False, \n",
    "            annot_kws={\"size\": 20, \"fontweight\": \"bold\"})  # Set annotation font size and bold\n",
    "\n",
    "\n",
    "# Increase font size for axis labels and title\n",
    "plt.xlabel('Predicted Label ', fontsize=16, fontweight = 'bold')\n",
    "plt.ylabel('True Label', fontsize=16, fontweight = 'bold')\n",
    "\n",
    "# Additional step: Use plt.setp() to make tick labels bold\n",
    "plt.setp(plt.gca().get_xticklabels(), fontweight='bold')  # Set x-tick labels to bold\n",
    "plt.setp(plt.gca().get_yticklabels(), fontweight='bold')  # Set y-tick labels to bold\n",
    "\n",
    "# Increase tick label font size\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Save the figure with 400 DPI\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"confusion_matrix_SNR5_BIN_data_ViT.png\"), dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_indices = np.where(y_true != y_pred)[0]\n",
    "print(\"Misclassified sample indices:\", misclassified_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
